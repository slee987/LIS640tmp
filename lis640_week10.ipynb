{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lis640_week10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slee987/LIS640tmp/blob/main/lis640_week10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI1t86uZAqpj"
      },
      "source": [
        "## 1 Set Up Environment\n",
        "\n",
        "Download CRFsuite on your computer: https://www.chokkan.org/software/crfsuite/\n",
        "* Windows: https://github.com/downloads/chokkan/crfsuite/crfsuite-0.12_win32.zip\n",
        "* Linux: https://github.com/downloads/chokkan/crfsuite/crfsuite-0.12-x86_64.tar.gz\n",
        "* Mac: build your own from source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsMJNcX4QLAR"
      },
      "source": [
        "## 2 Explore the CoNLL 2003 NER dataset\n",
        "\n",
        "Download the dataset (three files) from Canvas:\n",
        "* training set: CoNLL2003_ner_train.txt\n",
        "* validation set: CoNLL2003_ner_valid.txt\n",
        "* test set: CoNLL2003_ner_test.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMz-59pB0z7T"
      },
      "source": [
        "# utility functions for reading the dataset\n",
        "\n",
        "def load_dataset(path):\n",
        "    sents = []\n",
        "    with open(path) as f:\n",
        "        sent = []\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip()\n",
        "            if len(line)==0 or ( len(line)>=10 and line[:10]=='-DOCSTART-' ):\n",
        "                if len(sent)>0:\n",
        "                    sents.append(sent)\n",
        "                    sent = []\n",
        "            else:\n",
        "                token = line.split(' ')\n",
        "                assert len(token)==4\n",
        "                sent.append(token)\n",
        "    return sents\n",
        "\n",
        "path_train = 'CoNLL2003_ner_train.txt'\n",
        "path_valid = 'CoNLL2003_ner_valid.txt'\n",
        "path_test = 'CoNLL2003_ner_test.txt'\n",
        "\n",
        "train = load_dataset(path_train)\n",
        "valid = load_dataset(path_valid)\n",
        "test = load_dataset(path_test)\n",
        "\n",
        "print(len(train), len(valid), len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIqeivoX3tw6"
      },
      "source": [
        "# each sentence is a list of tokens (including the word, its POS tag, NP tag, and NER tag)\n",
        "\n",
        "train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMRLH8kE0z-1"
      },
      "source": [
        "train[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV7y76-l9vnS"
      },
      "source": [
        "## 3 Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2CoLcgv00Bz"
      },
      "source": [
        "# feature template functions\n",
        "\n",
        "import re\n",
        "\n",
        "# w[offset]=? for the ith word in a sentence\n",
        "def feat_w(sent, i, offset):\n",
        "    if i+offset<0:\n",
        "        return [ 'w[%d]=%s' % (offset, '<S>') ]\n",
        "    if i+offset>=len(sent):\n",
        "        return [ 'w[%d]=%s' % (offset, '</S>') ]\n",
        "    else:\n",
        "        return [ 'w[%d]=%s' % (offset, sent[i+offset][0]) ]\n",
        "\n",
        "# pos[offset]=? for the ith word in a sentence\n",
        "def feat_pos(sent, i, offset):\n",
        "    if i+offset<0:\n",
        "        return [ 'pos[%d]=%s' % (offset, '<S>') ]\n",
        "    if i+offset>=len(sent):\n",
        "        return [ 'pos[%d]=%s' % (offset, '</S>') ]\n",
        "    else:\n",
        "        return [ 'pos[%d]=%s' % (offset, sent[i+offset][1]) ]\n",
        "\n",
        "# character k-gram for the ith word in a sentence\n",
        "def feat_charngram(sent, i, k):\n",
        "    return [ ('char-%dgram='%k)+sent[i][0][j:j+k] for j in range(len(sent[i][0])-k+1) ]\n",
        "\n",
        "# a simple word shape feature: uppercase letter-->X, lowercase-->x, digit-->d\n",
        "def feat_wordshape(sent, i):\n",
        "    shape = re.sub('[A-Z]', 'X', sent[i][0])\n",
        "    shape = re.sub('[a-z]', 'x', shape)\n",
        "    shape = re.sub('[0-9]', 'd', shape)\n",
        "    return [ 'shape='+shape ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9rj9PYp00Ez"
      },
      "source": [
        "feat_charngram( train[0], 0, 2 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdI8UNY800Hf"
      },
      "source": [
        "feat_wordshape( train[0], 0 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhxQ2mbI9vnT"
      },
      "source": [
        "# output features to a file (tab separated)\n",
        "\n",
        "def output_feature_file( path, sents ):\n",
        "    f = open(path, 'w')\n",
        "    for sent in sents:\n",
        "        for i in range(len(sent)):\n",
        "\n",
        "            label = sent[i][3]\n",
        "\n",
        "            feats_w = feat_w(sent, i, 0)\n",
        "            feats_w_next = feat_w(sent, i, 1)\n",
        "            feats_w_next2 = feat_w(sent, i, 2)\n",
        "            feats_w_prev = feat_w(sent, i, -1)\n",
        "            feats_w_prev2 = feat_w(sent, i, -2)\n",
        "\n",
        "            feats_pos = feat_pos(sent, i, 0)\n",
        "            feats_pos_next = feat_pos(sent, i, 1)\n",
        "            feats_pos_next2 = feat_pos(sent, i, 2)\n",
        "            feats_pos_prev = feat_pos(sent, i, -1)\n",
        "            feats_pos_prev2 = feat_pos(sent, i, -2)\n",
        "\n",
        "            feat_3gram = feat_charngram(sent, i, 3)\n",
        "            feat_4gram = feat_charngram(sent, i, 4)\n",
        "\n",
        "            feat_shape = feat_wordshape(sent, i)\n",
        "\n",
        "            feats = feats_w+feats_w_next+feats_w_next2+feats_w_prev+feats_w_prev2 \\\n",
        "                + feats_pos+feats_pos_next+feats_pos_next2+feats_pos_prev+feats_pos_prev2 \\\n",
        "                + feat_3gram + feat_4gram + feat_shape\n",
        "\n",
        "            f.write( label + '\\t' + '\\t'.join(feats) + '\\n' )\n",
        "            \n",
        "        f.write('\\n')\n",
        "        \n",
        "    f.close()        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcMViRaT9vnU"
      },
      "source": [
        "output_feature_file( 'feats_train.txt', train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cCnTZ3y9vnU"
      },
      "source": [
        "output_feature_file( 'feats_test.txt', test )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDYp2KZE9vnU"
      },
      "source": [
        "## 4 Train & Test Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-82FkE2COPxK"
      },
      "source": [
        "Download the CRF suite (binaries or build on your own) and go to /bin folder. There will be an excutable file named crfsuite.\n",
        "\n",
        "Help INFO: crfsuite --help\n",
        "\n",
        "Training Help INFO: crfsuite learn --help\n",
        "\n",
        "Testing Help INFO: crfsuite tag --help\n",
        "\n",
        "Dump model Help INFO: crfsuite dump --help\n",
        "\n",
        "https://www.chokkan.org/software/crfsuite/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCkigzfSNIAH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}